{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-17T22:27:16.039639Z",
     "start_time": "2022-01-17T22:27:15.841267Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import math\n",
    "from time import time\n",
    "import editdistance\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from linkage.derived import EntityFinder\n",
    "from linkage.core.classifier import EntityPredicate, ScorePredicate, comparators, RulesBasedClassifier\n",
    "from linkage.core.clustering.disjoint_set_clusters import get_clusters\n",
    "import scipy \n",
    "\n",
    "BUILD_DIR = \"/build/paper_benchmarks/music\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Linkage on MusicBrainz dataset\n",
    "\n",
    "In this exercise, we compute the accuracy of linkage on a public dataset containing 20k records from the [MusicBrainz](https://musicbrainz.org/) database \n",
    "\n",
    "\n",
    "### Music Dataset\n",
    "\n",
    "The dataset, along with some papers published on it, can be found [here](https://dbs.uni-leipzig.de/research/projects/object_matching/benchmark_datasets_for_entity_resolution)\n",
    "\n",
    "5 sources\n",
    "\n",
    "Here is a description of the data:\n",
    "\n",
    "- TID: a unique record's id (in the complete dataset). <br/>\n",
    "- CID: cluster id (records having the same CID are duplicate) <br/>\n",
    "- CTID: a unique id within a cluster (if two records belong to the same cluster they will have the same CID but different CTIDs). These ids (CTID) start with 1 and grow until cluster size. <br/>\n",
    "- SourceID: identifies to which source a record belongs (there are five sources). The sources are deduplicated. <br/>\n",
    "- Id: the original id from the source. Each source has its own Id-Format. Uniqueness is not guaranteed!! (can be ignored). <br/>\n",
    "- number: track or song number in the album. <br/>\n",
    "- length: the length of the track. <br/>\n",
    "- artist: the interpreter (artist or band) of the track. <br/>\n",
    "- year: date of publication. <br/>\n",
    "- language: language of the track. <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-17T05:11:00.608891Z",
     "start_time": "2022-01-17T05:10:58.887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 19375 X 13\n",
      "Number of clusters: 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TID</th>\n",
       "      <th>CID</th>\n",
       "      <th>CTID</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>length</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>CID_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>MBox7368722-HH</td>\n",
       "      <td>9</td>\n",
       "      <td>Daniel Balavoine - L'enfant aux yeux d'Italie</td>\n",
       "      <td>219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>De vous à elle en passant par moi</td>\n",
       "      <td>75</td>\n",
       "      <td>French</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15183</th>\n",
       "      <td>15184</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11854016MB-01</td>\n",
       "      <td>9</td>\n",
       "      <td>L'enfant aux yeux d'Italie - De vous à elle en...</td>\n",
       "      <td>3.663</td>\n",
       "      <td>Daniel Balavoine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'75</td>\n",
       "      <td>French</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14721</th>\n",
       "      <td>14722</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6183919MB-01</td>\n",
       "      <td>17</td>\n",
       "      <td>Mustard Gas - There and Back Again Lane</td>\n",
       "      <td>2.15</td>\n",
       "      <td>Action Painting!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'95</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>MBox38440522-HH</td>\n",
       "      <td>17</td>\n",
       "      <td>Action PAINTING! - Mustard Gas</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There and Back Again Lane</td>\n",
       "      <td>95</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4489993</td>\n",
       "      <td>10</td>\n",
       "      <td>Your Grace</td>\n",
       "      <td>unk.</td>\n",
       "      <td>Kathy Troccoli</td>\n",
       "      <td>Comfort</td>\n",
       "      <td>2005</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TID  CID  CTID  SourceID               id number  \\\n",
       "0          1    1     1         2   MBox7368722-HH      9   \n",
       "15183  15184    1     2         3    11854016MB-01      9   \n",
       "14721  14722    2     2         3     6183919MB-01     17   \n",
       "2          3    2     1         2  MBox38440522-HH     17   \n",
       "3          4    3     1         5          4489993     10   \n",
       "\n",
       "                                                   title length  \\\n",
       "0          Daniel Balavoine - L'enfant aux yeux d'Italie    219   \n",
       "15183  L'enfant aux yeux d'Italie - De vous à elle en...  3.663   \n",
       "14721            Mustard Gas - There and Back Again Lane   2.15   \n",
       "2                         Action PAINTING! - Mustard Gas    129   \n",
       "3                                             Your Grace   unk.   \n",
       "\n",
       "                 artist                              album  year language  \\\n",
       "0                   NaN  De vous à elle en passant par moi    75   French   \n",
       "15183  Daniel Balavoine                                NaN   '75   French   \n",
       "14721  Action Painting!                                NaN   '95  English   \n",
       "2                   NaN          There and Back Again Lane    95  English   \n",
       "3        Kathy Troccoli                            Comfort  2005  English   \n",
       "\n",
       "       CID_size  \n",
       "0             2  \n",
       "15183         2  \n",
       "14721         2  \n",
       "2             2  \n",
       "3             1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_data():\n",
    "    df = pd.read_csv(\"/build/musicbrainz-20k.csv\")  # downloaded from the link mentioned above\n",
    "    df['TID'] = df.TID.astype(str)\n",
    "    cluster_size = df.groupby(\"CID\").TID.count()\n",
    "    df['CID_size'] = df.CID.map(cluster_size)\n",
    "    print(\"Shape: %d X %d\" % df.shape)\n",
    "    print(\"Number of clusters: %d\" % df.CID.nunique())\n",
    "    return df\n",
    "\n",
    "df = fetch_data()\n",
    "df.sort_values(\"CID\").head(5)  # CID identifies clusters of duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T06:43:52.642154Z",
     "start_time": "2021-09-14T06:43:52.629972Z"
    }
   },
   "source": [
    "### Initialize Linkage\n",
    "\n",
    "Configure linkage to run on this dataset. \n",
    "\n",
    "We use a simple unsupervised classifier here, which just checks whether the matching score is above the given threshold to classify it as a match. It is called \"unsupervised\" because the algorithm is not learning patterns from labeled data. We just try a few thresholds and adjust them depending on the clusters we get. If the clusters are too big, we reduce the threshold; if they are too small, we increase it. We do not use true labels to identify thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-17T05:11:00.610712Z",
     "start_time": "2022-01-17T05:10:58.890Z"
    }
   },
   "outputs": [],
   "source": [
    "def deduplicate(df, th, min_threshold: float = 0.2, num_best: int = 5):\n",
    "    \n",
    "    # Describe columns to be used\n",
    "    column_info = {\n",
    "        'TID': {'type': 'string', 'block': False, 'classify': False, 'primary_key': True},\n",
    "        'title': {'type': 'string', 'block': True, 'classify': True},\n",
    "        'artist': {'type': 'string', 'block': True, 'classify': True},\n",
    "        'album': {'type': 'string', 'block': True, 'classify': True},\n",
    "        'language': {'type': 'string', 'block': True, 'classify': True},  \n",
    "        'number': {'type': 'string', 'block': True, 'classify': True},    \n",
    "        'length': {'type': 'string', 'block': True, 'classify': True},    \n",
    "        'year': {'type': 'string', 'block': True, 'classify': True},    \n",
    "    }\n",
    "\n",
    "    # Use a simple threshold-based \"unsupervised\" classifer. This classifer can be changed to add more \n",
    "    # \"semi-supervised\" rules, but for the scope of this paper, we are not reporting the benchmarks \n",
    "    # from a supervised classifer – since training a model on the true labels provided in the dataset is not a fair \n",
    "    # comparison against benchmarks from papers which do not use the true labels.\n",
    "    rbc_classifier = RulesBasedClassifier([\n",
    "        [\n",
    "        ScorePredicate(threshold=th) \n",
    "        ]      \n",
    "    ])\n",
    "\n",
    "    # Initialize EntityFinder class, which allows us to run entity resolution with a simple configuration\n",
    "    ef = EntityFinder(column_info, classifier=rbc_classifier, build_dir=BUILD_DIR, query_method=\"inverted_index\") \n",
    "    # create index on the dataset for fast processing; use out-of-core to use low memory.\n",
    "    ef.create_index(df, out_of_core=True)\n",
    "    ef.save() \n",
    "    del ef\n",
    "    \n",
    "    # In order to make sure the save/load function works, we delete the index object and re-load it from disk\n",
    "    ef = EntityFinder.Load(BUILD_DIR, mmap=True, classifier=rbc_classifier)  # seq index requires save and load  \n",
    "    # We search for matching entities on the same dataframe. `search` returns a list of matches. \n",
    "    # Each entry in the list contains the original entity, and a list of matching entities with \n",
    "    # corresponding matching scores from the Indexer. These scores, by default, are the cosine similarities \n",
    "    # between the entities. A matching entities has scores above the threshold specified in the classifier\n",
    "    matches = ef.search(df, min_threshold=min_threshold, num_best=num_best, chunk_size=500000)\n",
    "\n",
    "    # Form clusters between matching entities\n",
    "    clusters, scores = get_clusters(matches)\n",
    "\n",
    "    # Add clustering information to the original dataframe, and we are done!\n",
    "    df['cluster_number'] = clusters\n",
    "    df['cluster_score'] = df.cluster_number.apply(lambda i: scores.loc[(i, 'cluster_score')])\n",
    "    df['lowest_score'] = df.cluster_number.apply(lambda i: scores.loc[(i, 'lowest_score')])\n",
    "    df['cluster_size'] = df.cluster_number.apply(lambda i: scores.loc[(i, 'size')])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCr(n, r):\n",
    "    \"\"\" N Choose R\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return scipy.special.comb(n, r)\n",
    "\n",
    "def compute_tp_pp(tdf, col):\n",
    "    \"\"\"\n",
    "    Compute true positives and predicted positives for the given dataframe and the column in question.\n",
    "    If there are five entities in a predicted cluster, the predicted positives are 5 Choose 2 = 10\n",
    "    If the corresponding column `col`, which contains ground truth, has a cluster of 3 entities, and another \n",
    "    cluster of 2, the true positives are (3 Choose 2) + (2 choose 2) = 5\n",
    "    So, in this example, there were 10 predicted links (PP), but only 5 true links (TP)\n",
    "    This can be used for computing overall precision of the algorithm. \n",
    "    \n",
    "    The definition can be reversed: we can also compute positives and true positives\n",
    "    using this function, which would cumulatively give us the recall of the algoritm\n",
    "    \n",
    "    Clusters containing only one entity are not counted towards either metrics.\n",
    "    \"\"\"\n",
    "    if len(tdf) == 1:  # Cluster contains one entry, ignore\n",
    "        return pd.Series({'pps': 0, 'tps': 0})\n",
    "    \n",
    "    pps = nCr(len(tdf), 2)  # predicted positives are just N choose 2\n",
    "    \n",
    "    # True positives is the \\sum_{i=1}^{n} (N_i Choose 2) where N_i is the number of elements in\n",
    "    # each predicted cluster and there are n predicted clusters. We ignore clusters of size 1.\n",
    "    vcs = tdf[col].value_counts()    \n",
    "    tps = vcs[vcs > 1].apply(lambda x: nCr(x, 2)).sum()  \n",
    "    \n",
    "    return pd.Series({'pps': pps, 'tps': tps})\n",
    "    \n",
    "def compute_precision_recall(df):\n",
    "    \"\"\" Compute precision recall metrics by \n",
    "        - calling `compute_tp_pp` for each predicted cluster (for precision) and \n",
    "          each true cluster (for recall) \n",
    "        - Then, compute sum(tps) / sum(pps)\n",
    "    \"\"\"\n",
    "    df_precision = df.groupby(\"cluster_number\").apply(lambda x: compute_tp_pp(x, 'CID'))\n",
    "    df_recall = df.groupby(\"CID\").apply(lambda x: compute_tp_pp(x, 'cluster_number'))\n",
    "    precision = df_precision.tps.sum() / df_precision.pps.sum()\n",
    "    recall = df_recall.tps.sum() / df_recall.pps.sum()\n",
    "    \n",
    "    f_measure =  2 * precision * recall / (precision + recall)\n",
    "    num_clusters = df.cluster_number.nunique()    \n",
    "    return {\n",
    "        \"precision\": precision, \n",
    "        \"recall\": recall, \n",
    "        \"f_measure\": f_measure, \n",
    "        \"num_clusters\": num_clusters, \n",
    "        \"precision_identified_links\": df_precision.sum()['pps'],\n",
    "        \"precision_correctly_identified_links\": df_precision.sum()['tps'],\n",
    "        \"recall_num_links\": df_recall.sum()['pps'],\n",
    "        \"recall_correctly_identified_links\": df_recall.sum()['tps']\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Linkage and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:20:07,631 : INFO : Ingesting data into an OOC embedded database\n",
      "2022-01-20 20:20:07,632 : INFO : Phone number columns: []\n",
      "2022-01-20 20:20:07,633 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:20:07,634 : INFO : Address columns: []\n",
      "2022-01-20 20:20:08,320 : INFO : Blocking 19375 records on columns ['title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:20:08,418 : INFO : Using out-of-core tokenizer \n",
      "2022-01-20 20:20:16,238 : INFO : TFIDF blocker created with 31991 tokens\n",
      "2022-01-20 20:20:16,240 : INFO : Saving EntityFinder blocked model to /build/paper_benchmarks/music\n",
      "2022-01-20 20:20:17,387 : INFO : Loading using memorymap: r\n",
      "2022-01-20 20:20:17,498 : INFO : Set dummy = -1\n",
      "2022-01-20 20:20:17,499 : INFO : Collecting dictionary stat\n",
      "2022-01-20 20:20:17,516 : INFO : Actually creating the index\n",
      "2022-01-20 20:20:17,558 : INFO : Sanity check\n",
      "2022-01-20 20:20:17,570 : INFO : Phone number columns: []\n",
      "2022-01-20 20:20:17,571 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:20:17,572 : INFO : Address columns: []\n",
      "2022-01-20 20:20:17,861 : INFO : Searching through blocked/indexed data to pick top 10 matches\n",
      "2022-01-20 20:20:29,526 : INFO : Chunk 1 finished in 9.71 seconds\n",
      "2022-01-20 20:20:29,534 : INFO : Total search time: 9.72 seconds\n",
      "2022-01-20 20:20:29,553 : INFO : Classifier picking the best matches\n",
      "2022-01-20 20:20:29,861 : INFO : Classifier finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8758509990590579,\n",
       " 'recall': 0.9737846153846154,\n",
       " 'f_measure': 0.9222251362298568,\n",
       " 'num_clusters': 9828,\n",
       " 'precision_identified_links': 18067.0,\n",
       " 'precision_correctly_identified_links': 15824.0,\n",
       " 'recall_num_links': 16250.0,\n",
       " 'recall_correctly_identified_links': 15824.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = deduplicate(df.copy(deep=True), th=0.45, min_threshold=0.3, num_best=10)\n",
    "metrics = compute_precision_recall(df_output)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall is pretty high but the precision is low. This is because a few clusters are too big; and since we compute N choose 2, the errors get squared. Just fixing a couple of rogue clusters improves the precision greatly.\n",
    "\n",
    "To \"fix\" these large clusters, we do not use the true labels, since that would be cheating!. We use `cluster_score` returned by Linkage, which gives a measure of the \"connectivity\" of edges in a cluster. \n",
    "\n",
    "It is computed as: number of actual edges in the cluster /  maximum possible edges\n",
    "\n",
    "maximum possible edges = 2 * (N choose 2)\n",
    "\n",
    "For example, if a cluster has three entities A, B, C and the edges are  A -> B, C -> B, B ->C\n",
    "then, the cluster score is `3 / (2*(3 Choose 2))`  = `3 / 6` = `0.5`\n",
    "\n",
    "If the `cluster_score` for a given cluser is below the threshold (0.8 in this case), we send the cluster to match again with a higher threshold.\n",
    "We call this approach \"iterative connected components\" (apologies if the name is already taken by a different algorithm in the literature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break clusters with low cluster_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-17T05:11:00.612336Z",
     "start_time": "2022-01-17T05:10:58.894Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:21:09,419 : INFO : Ingesting data into an OOC embedded database\n",
      "2022-01-20 20:21:09,421 : INFO : Phone number columns: []\n",
      "2022-01-20 20:21:09,424 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:21:09,429 : INFO : Address columns: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: 19375 X 13\n",
      "Number of clusters: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:21:10,113 : INFO : Blocking 19375 records on columns ['title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:21:10,211 : INFO : Using out-of-core tokenizer \n",
      "2022-01-20 20:21:16,721 : INFO : TFIDF blocker created with 31991 tokens\n",
      "2022-01-20 20:21:16,723 : INFO : Saving EntityFinder blocked model to /build/paper_benchmarks/music\n",
      "2022-01-20 20:21:16,923 : INFO : Loading using memorymap: r\n",
      "2022-01-20 20:21:17,023 : INFO : Set dummy = -1\n",
      "2022-01-20 20:21:17,024 : INFO : Collecting dictionary stat\n",
      "2022-01-20 20:21:17,041 : INFO : Actually creating the index\n",
      "2022-01-20 20:21:17,078 : INFO : Sanity check\n",
      "2022-01-20 20:21:17,092 : INFO : Phone number columns: []\n",
      "2022-01-20 20:21:17,093 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:21:17,093 : INFO : Address columns: []\n",
      "2022-01-20 20:21:17,383 : INFO : Searching through blocked/indexed data to pick top 10 matches\n",
      "2022-01-20 20:21:28,973 : INFO : Chunk 1 finished in 9.80 seconds\n",
      "2022-01-20 20:21:28,981 : INFO : Total search time: 9.81 seconds\n",
      "2022-01-20 20:21:29,001 : INFO : Classifier picking the best matches\n",
      "2022-01-20 20:21:29,132 : INFO : Classifier finished\n",
      "2022-01-20 20:22:07,992 : INFO : Ingesting data into an OOC embedded database\n",
      "2022-01-20 20:22:07,993 : INFO : Phone number columns: []\n",
      "2022-01-20 20:22:07,994 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:22:07,995 : INFO : Address columns: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran for threshold: 0.45\n",
      "{'precision': 0.8758509990590579, 'recall': 0.9737846153846154, 'f_measure': 0.9222251362298568, 'num_clusters': 9828, 'precision_identified_links': 18067.0, 'precision_correctly_identified_links': 15824.0, 'recall_num_links': 16250.0, 'recall_correctly_identified_links': 15824.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:22:08,559 : INFO : Blocking 19375 records on columns ['title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:22:08,614 : INFO : Using out-of-core tokenizer \n",
      "2022-01-20 20:22:13,872 : INFO : TFIDF blocker created with 31991 tokens\n",
      "2022-01-20 20:22:13,874 : INFO : Saving EntityFinder blocked model to /build/paper_benchmarks/music\n",
      "2022-01-20 20:22:14,084 : INFO : Loading using memorymap: r\n",
      "2022-01-20 20:22:14,182 : INFO : Set dummy = -1\n",
      "2022-01-20 20:22:14,184 : INFO : Collecting dictionary stat\n",
      "2022-01-20 20:22:14,201 : INFO : Actually creating the index\n",
      "2022-01-20 20:22:14,239 : INFO : Sanity check\n",
      "2022-01-20 20:22:14,252 : INFO : Phone number columns: []\n",
      "2022-01-20 20:22:14,253 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:22:14,254 : INFO : Address columns: []\n",
      "2022-01-20 20:22:14,550 : INFO : Searching through blocked/indexed data to pick top 10 matches\n",
      "2022-01-20 20:22:26,141 : INFO : Chunk 1 finished in 9.20 seconds\n",
      "2022-01-20 20:22:26,152 : INFO : Total search time: 9.22 seconds\n",
      "2022-01-20 20:22:26,172 : INFO : Classifier picking the best matches\n",
      "2022-01-20 20:22:26,306 : INFO : Classifier finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of potentially incorrect clusters: 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:23:06,926 : INFO : Ingesting data into an OOC embedded database\n",
      "2022-01-20 20:23:06,927 : INFO : Phone number columns: []\n",
      "2022-01-20 20:23:06,929 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:23:06,930 : INFO : Address columns: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran for threshold: 0.55\n",
      "{'precision': 0.940649966961014, 'recall': 0.9636307692307692, 'f_measure': 0.952001702282883, 'num_clusters': 10049, 'precision_identified_links': 16647.0, 'precision_correctly_identified_links': 15659.0, 'recall_num_links': 16250.0, 'recall_correctly_identified_links': 15659.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:23:07,573 : INFO : Blocking 19375 records on columns ['title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:23:07,672 : INFO : Using out-of-core tokenizer \n",
      "2022-01-20 20:23:14,064 : INFO : TFIDF blocker created with 31991 tokens\n",
      "2022-01-20 20:23:14,067 : INFO : Saving EntityFinder blocked model to /build/paper_benchmarks/music\n",
      "2022-01-20 20:23:14,264 : INFO : Loading using memorymap: r\n",
      "2022-01-20 20:23:14,321 : INFO : Set dummy = -1\n",
      "2022-01-20 20:23:14,322 : INFO : Collecting dictionary stat\n",
      "2022-01-20 20:23:14,334 : INFO : Actually creating the index\n",
      "2022-01-20 20:23:14,357 : INFO : Sanity check\n",
      "2022-01-20 20:23:14,367 : INFO : Phone number columns: []\n",
      "2022-01-20 20:23:14,368 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:23:14,369 : INFO : Address columns: []\n",
      "2022-01-20 20:23:14,567 : INFO : Searching through blocked/indexed data to pick top 10 matches\n",
      "2022-01-20 20:23:26,061 : INFO : Chunk 1 finished in 9.95 seconds\n",
      "2022-01-20 20:23:26,070 : INFO : Total search time: 9.96 seconds\n",
      "2022-01-20 20:23:26,090 : INFO : Classifier picking the best matches\n",
      "2022-01-20 20:23:26,221 : INFO : Classifier finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of potentially incorrect clusters: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:24:08,850 : INFO : Ingesting data into an OOC embedded database\n",
      "2022-01-20 20:24:08,852 : INFO : Phone number columns: []\n",
      "2022-01-20 20:24:08,853 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:24:08,854 : INFO : Address columns: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran for threshold: 0.65\n",
      "{'precision': 0.961147601933325, 'recall': 0.9545230769230769, 'f_measure': 0.9578238853896505, 'num_clusters': 10149, 'precision_identified_links': 16138.0, 'precision_correctly_identified_links': 15511.0, 'recall_num_links': 16250.0, 'recall_correctly_identified_links': 15511.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 20:24:09,633 : INFO : Blocking 19375 records on columns ['title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:24:09,720 : INFO : Using out-of-core tokenizer \n",
      "2022-01-20 20:24:17,974 : INFO : TFIDF blocker created with 31991 tokens\n",
      "2022-01-20 20:24:17,976 : INFO : Saving EntityFinder blocked model to /build/paper_benchmarks/music\n",
      "2022-01-20 20:24:18,124 : INFO : Loading using memorymap: r\n",
      "2022-01-20 20:24:18,180 : INFO : Set dummy = -1\n",
      "2022-01-20 20:24:18,180 : INFO : Collecting dictionary stat\n",
      "2022-01-20 20:24:18,194 : INFO : Actually creating the index\n",
      "2022-01-20 20:24:18,218 : INFO : Sanity check\n",
      "2022-01-20 20:24:18,228 : INFO : Phone number columns: []\n",
      "2022-01-20 20:24:18,228 : INFO : String columns: ['TID', 'title', 'artist', 'album', 'language', 'number', 'length', 'year']\n",
      "2022-01-20 20:24:18,229 : INFO : Address columns: []\n",
      "2022-01-20 20:24:18,446 : INFO : Searching through blocked/indexed data to pick top 10 matches\n",
      "2022-01-20 20:24:32,354 : INFO : Chunk 1 finished in 12.13 seconds\n",
      "2022-01-20 20:24:32,364 : INFO : Total search time: 12.13 seconds\n",
      "2022-01-20 20:24:32,385 : INFO : Classifier picking the best matches\n",
      "2022-01-20 20:24:32,519 : INFO : Classifier finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of potentially incorrect clusters: 16\n",
      "Ran for threshold: 0.75\n",
      "{'precision': 0.9643435980551054, 'recall': 0.952, 'f_measure': 0.9581320450885668, 'num_clusters': 10169, 'precision_identified_links': 16042.0, 'precision_correctly_identified_links': 15470.0, 'recall_num_links': 16250.0, 'recall_correctly_identified_links': 15470.0}\n"
     ]
    }
   ],
   "source": [
    "MAX_NUM = 100000000  # Trick used to generate unique cluster numbers\n",
    "TH_CLUSTER_BREAK = 0.8\n",
    "\n",
    "def run(th):\n",
    "    \"\"\"\n",
    "    Runs deduplication iteratively and breaks down clusters with low `cluster_score` by sending them \n",
    "    through LINKAGE with a higher threshold\n",
    "    :param th: threshold to run the algorithm on\n",
    "    \"\"\"\n",
    "    df = fetch_data()\n",
    "    df.set_index(\"TID\", inplace=True, drop=False)\n",
    "    for th in np.arange(th, th + 0.31, 0.1):  # run 3 iterations\n",
    "        df_next_th = deduplicate(df.copy(deep=True), th=th, min_threshold=0.3, num_best=10)\n",
    "        \n",
    "        # run this block the second time, to identify and fix clsuters with low cluster_score\n",
    "        if \"cluster_number\" in df.columns.tolist():\n",
    "            # identify clsuters with low cluster_score\n",
    "            potentially_incorrect_clusters = df[df.cluster_score <= TH_CLUSTER_BREAK].cluster_number.unique()\n",
    "            mask = df.cluster_number.isin(potentially_incorrect_clusters)\n",
    "            df_bad = df[mask]\n",
    "            print(\"Number of potentially incorrect clusters: %d\" % len(potentially_incorrect_clusters))\n",
    "            \n",
    "            # Replace bad clusters with new clusters run with a higher threshold\n",
    "            df_bad_fixed = df_next_th[df_next_th.TID.isin(df_bad.TID)].set_index(\"TID\", drop=False)\n",
    "            assert df_bad_fixed.shape[0] == df_bad.shape[0]\n",
    "            for col in [\"cluster_number\", \"cluster_score\", \"lowest_score\", \"cluster_size\"]:\n",
    "                # We use a \"hack\" here to make sure the new cluster numbers are not overlapping with old ones\n",
    "                # Mutiplying MAX_NUM*th should generate a new set of cluster numbers \n",
    "                # as long as MAX_NUM * 0.1 > len(df)\n",
    "                df.loc[df_bad_fixed.TID, col] = df_bad_fixed[col] + (MAX_NUM*th if col == 'cluster_number' else 0)\n",
    "                \n",
    "        else: # first time; prepare for the next run\n",
    "            df = df_next_th\n",
    "\n",
    "        out = compute_precision_recall(df)\n",
    "        print(\"Ran for threshold: %.2f\" %(th))\n",
    "        print(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "result = run(0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.9643435980551054,\n",
       " 'recall': 0.952,\n",
       " 'f_measure': 0.9581320450885668,\n",
       " 'num_clusters': 10169,\n",
       " 'precision_identified_links': 16042.0,\n",
       " 'precision_correctly_identified_links': 15470.0,\n",
       " 'recall_num_links': 16250.0,\n",
       " 'recall_correctly_identified_links': 15470.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
